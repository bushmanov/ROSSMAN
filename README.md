# ROSSMAN

1. `Benchmark_Plan.ipynb` -- лист всех тестируемых моделей с пояснениями что на входе, что на выходе, фичи и их количество.

2. `CV.ods` -- результат CV, таблица в формате Open Office.  

3. `benchmark20_mine_prepro_grouped.ipynb` + `metafeature_xgb_benchmark20.R` -- связка подготовки данных в Python + 
тренировка XGBoost в R :  

- `benchmark20_mine_prepro_grouped.ipynb` :  
  - чистим данные (NaN, outliers)
  - готовим фичи  
  - делаем фолды для CV  
  - выгружаем в формате `.csv`  
  
- `metafeature_xgb_benchmark20.R`:  
  - тренируем 3 разных модели с двумя разными **известными** глубинами  
  - делаем метафичи для train и для test
  - кастоимизированная looss-function  
  
4. `Cluster_by_Euclidean_Distance.ipynb` -- попытка кластеризации магазинов по "похожести" продаж, с последующей визуализацией.

5. `Resids_analysis.ipynb` -- анализ остатков на i.i.d., т.е. поиск ответа на вопрос: "Насколько XGBoost"  в-принципе 
применим для анализа данной задачи с временными рядами.  

6. `Predicting_with_Pandas.ipynb` -- попытка "очистить" продажи от эффекта "Promo" с визуализацией  

7. `Ensembling_Plots_Feature_1_2_3.ipynb` -- визуализация стэкинга различных моделей. Интересные наблюдения:  
  - "недотренированность" моделей не так критична   
  - 3-я модель (F3) ведет себя "странно", что впоследствии нашло объяснение при более пристальном анализе данной
  модели на train сэте: модель оказалась "перетренированной", пришлось "облегчить" её от нерелевантных фич. 
